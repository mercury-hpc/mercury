UCX design notes
----------------

The UCX API called UCP appears to provide all of the facilities that
Mercury's NA interface requires.  NA and UCP operate at similar levels
of abstraction.

UCP is built on UCT.  UCT operates closer to the hardware, and it offers
more degrees of freedom.  At first blush, writing an NA plugin using UCT
entails tracking more communications state than we have to if we use UCP.
For example, using UCT, our plugin may be responsible to both defragment
received messages and select the copy mode (immediate, bounce, zero-copy).
UCP handles those details for us.

It does not look like our plugin can usefully blend the UCP & UCT APIs
by, say, writing the plugin using UCP, first, and then rewriting fast
paths with UCT.

I have more to learn about UCT, but for a prototype plugin, we probably
should use UCP.  Then, if UCP performance disappoints us, then we can
investigate the use of UCT.

Initialize/Finalize
-------------------

NA <-> UCP correspondence

na_class_t: ucp_context_h, a UCP application context

    ucp_init()/_cleanup()

na_context_t: ucp_worker_h, a worker "represents an instance of a local
    communication resource and the progress engine associated with it."

    ucp_worker_create()/_destroy()

In NA, there is one address per na_class_t, but in UCX it appears that
there is one address per worker.  So there may be a mismatch here.
Possibly set up only one worker per class instead of one worker per
context.

Connection management (connected/unconnected)
---------------------------------------------

na_addr_t: ucp_address_t, variable-length, opaque address.

    Our "concrete" na_addr_t should look like this,

	struct {
		ucp_address_t *addr;
		size_t addrlen;
	};

    All of the na_class_ops methods having anything to do with addresses
    seem to have straightforward implementations.

    BTW, UCX defines ucp_address_t like this,

	typedef struct ucp_address ucp_address_t;

    UCX never defines `struct ucp_address`.  UCP and its clients use
    `ucp_address_t *`, but there is not sufficient information to use a
    `ucp_address_t`-type variable or parameter.  This is a cute trick
    that contributes to type safety.  Mercury could use the same trick
    with na_addr_t.  Individual plugins could (I think) have private
    na_addr_t definitions.

    We can treat the ucp_address_t like an array of bytes.

ucs_status_t ucp_worker_get_address(ucp_worker_h worker, ucp_address_t
    **address_p, size_t *address_length_p): return the worker's opaque
    address and its length.  Presumably, we can share this out-of-band
    with communication peers.

Before a program can communicate with a peer, it has to use the peer's
address to create an "endpoint" (ucp_ep_h).  It's possible to start
communication with the endpoint immediately.  That is, you don't have
to initiate a connection, wait for the connection to finish, et cetera,
like you do with a BSD socket.

I was surprised to find no peer-discovery methods in UCX.  That is,
you cannot use UCX to indicate your membership in a communications group
and to list the other group members by address.

There is no broadcast/multicast in UCX.

Between a worker and each of its endpoints there is a reliable data
stream.

Tag matching and small messaging
--------------------------------

ucs_status_ptr_t ucp_tag_send_nb(ucp_ep_h ep, const void *buffer,
    size_t count, ucp_datatype_t datatype, ucp_tag_t tag,
    ucp_send_callback_t cb): non-blocking tagged send

ucs_status_ptr_t ucp_tag_recv_nb(ucp_worker_h worker, void *buffer,
    size_t count, ucp_datatype_t datatype, ucp_tag_t tag,
    ucp_tag_t tag_mask, ucp_tag_recv_callback_t cb): non-blocking
    tagged receive

Using these routines, you can perform scatter-gather I/O by passing a
`datatype` of `UCP_DATATYPE_IOV` and a vector of `count` `ucp_dt_iov_t`
in `buffer`.

There are various other tagged send/receive functions.

All of the UCP routines abstract over immediate/eager/rendezvous
maximum data length, so a maximum message size is not defined.

RMA
---

Memory registration:

ucs_status_t ucp_mem_map(ucp_context_h context,
    const ucp_mem_map_params_t *params, ucp_mem_h *memh_p): register
    the memory region described by `params` or, if `params->address` is
    NULL, allocate a region `params->length` bytes long and register it.
    Store a handle for the registered region at `memh_p`.

ucs_status_t ucp_mem_unmap(ucp_context_h context, ucp_mem_h memh):
    unregister a region (and free it if `ucp_mem_map` allocated it).

ucs_status_t ucp_rkey_pack(ucp_context_h context, ucp_mem_h memh,
    void **rkey_buffer_p, size_t *size_p): pack a remote access key for
    `memh` into the given buffer.  To share the key with a remote peer,
    send it all `*size_p` bytes of `*rkey_buffer_p`.

ucs_status_t ucp_ep_rkey_unpack(ucp_ep_h ep, const void *rkey_buffer,
    ucp_rkey_h *rkey_p): unpack the remote access key in `rkey_buffer` and
    store it at `rkey_p`.

ucs_status_ptr_t ucp_put_nb(ucp_ep_h ep, const void *buffer, size_t length,
    uint64_t remote_addr, ucp_rkey_h rkey, ucp_send_callback_t cb),
ucs_status_t ucp_put_nbi(ucp_ep_h ep, const void *buffer, size_t length,
    uint64_t remote_addr, ucp_rkey_h rkey): put `length`-byte `buffer`
    at `remote_addr` using access key `rkey`, with or without an explicit
    indication that UCP is finished with `buffer`.

The documentation has no specific guidance on the derivation and use of a
`uint64_t` remote address.

Progress
--------

ucp_worker_progress(worker) gives the progress engine an opportunity
    to run, returning non-zero if progress was made, 0 otherwise.

ucp_worker_wait(worker) blocks until an event has happened.

ucp_worker_get_efd(worker) returns a descriptor that we can add
    to a poll set.

ucp_worker_arm(worker) has to be called under some circumstances
    after the last ucp_worker_progress(worker) call but before
    ucp_worker_wait(worker) or polling the descriptor.

